{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alberba/Aprendizaje-Autom-tico/blob/main/18_Practica2/detectsegm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torchvision.ops.boxes import masks_to_boxes\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import cv2\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import torch\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "from torchvision.transforms.v2 import functional as F\n",
        "from torchvision.transforms import v2 as T\n",
        "from torchvision import tv_tensors\n",
        "from tqdm.auto import tqdm\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import random\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "iUynWK5gUXRR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.Caltech101(root='./dataAux', download=True, target_type='annotation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36YS_i-wUYzT",
        "outputId": "fd5a761c-8b93-4db7-9c64-81fc9b8d839f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz9e8ydBNRsW",
        "outputId": "82fed688-486a-454b-f24f-a5c0633cbd19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesadas 152 imágenes y 152 máscaras.\n"
          ]
        }
      ],
      "source": [
        "def process_images_and_masks(base_dir_images, base_dir_annotations):\n",
        "    \"\"\"\n",
        "    Procesa imágenes y máscaras de las clases 'buddha' y 'dalmatian'.\n",
        "\n",
        "    Args:\n",
        "        base_dir_images (str): Ruta base de las imágenes (101_ObjectCategories).\n",
        "        base_dir_annotations (str): Ruta base de las anotaciones.\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de imágenes procesadas como arrays de NumPy.\n",
        "        list: Lista de máscaras procesadas como arrays de NumPy.\n",
        "    \"\"\"\n",
        "    classes_to_process = {'buddha': 1, 'dalmatian': 2}\n",
        "    image_list = []\n",
        "    mask_list = []\n",
        "    class_list = []\n",
        "\n",
        "    for class_name, class_id in classes_to_process.items():\n",
        "        # Rutas de las subcarpetas\n",
        "        class_images_dir = os.path.join(base_dir_images, class_name)\n",
        "        class_annotations_dir = os.path.join(base_dir_annotations, class_name)\n",
        "\n",
        "        # Verifica si las carpetas existen\n",
        "        if not os.path.isdir(class_images_dir) or not os.path.isdir(class_annotations_dir):\n",
        "            print(f\"Carpeta no encontrada: {class_name}\")\n",
        "            continue\n",
        "\n",
        "        # Procesar las imágenes y las anotaciones\n",
        "        for annotation_file in os.listdir(class_annotations_dir):\n",
        "            if annotation_file.endswith('.mat'):\n",
        "                annotation_path = os.path.join(class_annotations_dir, annotation_file)\n",
        "                annotation_id = os.path.splitext(annotation_file)[0].split('_')[-1]\n",
        "\n",
        "                # Ruta de la imagen correspondiente\n",
        "                image_file = f\"image_{annotation_id}.jpg\"\n",
        "                image_path = os.path.join(class_images_dir, image_file)\n",
        "\n",
        "                if not os.path.exists(image_path):\n",
        "                    print(f\"Imagen no encontrada para {annotation_file}\")\n",
        "                    continue\n",
        "\n",
        "                # Cargar la anotación\n",
        "                mat_data = scipy.io.loadmat(annotation_path)\n",
        "                if 'obj_contour' not in mat_data:\n",
        "                    print(f\"'obj_contour' no encontrada en {annotation_file}\")\n",
        "                    continue\n",
        "\n",
        "                obj_contour = mat_data['obj_contour']  # Contorno de la máscara\n",
        "\n",
        "                # Cargar la imagen\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is None:\n",
        "                    print(f\"Error al cargar la imagen {image_path}\")\n",
        "                    continue\n",
        "\n",
        "                # Crear una máscara vacía del mismo tamaño que la imagen\n",
        "                mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
        "                boxcoord = mat_data['box_coord'].flatten()\n",
        "\n",
        "                # Dibujar el contorno en la máscara\n",
        "                contour_points = np.transpose(obj_contour)  # Shape (Y, 2)\n",
        "                contour_points[:, 0] += boxcoord[2]  # Ajustar X según x0 del bounding box\n",
        "                contour_points[:, 1] += boxcoord[0]  # Ajustar Y según y0 del bounding box\n",
        "                contour_points = contour_points.astype(np.int32)  # Asegurar tipo correcto\n",
        "\n",
        "                cv2.drawContours(mask, [contour_points], contourIdx=-1, color=1, thickness=-1)\n",
        "                #cv2.drawContours(image, [contour_points], contourIdx=-1, color=1, thickness=-1)\n",
        "\n",
        "                # Mostrar la imagen\n",
        "                # cv2_imshow(image)\n",
        "                # cv2.waitKey(0)\n",
        "                # cv2.destroyAllWindows()\n",
        "\n",
        "                # Agregar la imagen y la máscara a las listas\n",
        "                image_list.append(image)\n",
        "                mask_list.append(mask)\n",
        "                class_list.append(class_id)\n",
        "\n",
        "    return image_list, mask_list, class_list\n",
        "\n",
        "base_dir_images = \"./dataAux/caltech101/101_ObjectCategories\"\n",
        "base_dir_annotations = \"./dataAux/caltech101/Annotations\"\n",
        "images, masks, classes = process_images_and_masks(base_dir_images, base_dir_annotations)\n",
        "print(f\"Procesadas {len(images)} imágenes y {len(masks)} máscaras.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HkuVzfjINRsZ"
      },
      "outputs": [],
      "source": [
        "def augment_data(images, masks, classes):\n",
        "    \"\"\"\n",
        "    Realiza aumentos de datos en las imágenes y máscaras.\n",
        "\n",
        "    Args:\n",
        "        images (list): Lista de imágenes como arrays de NumPy.\n",
        "        masks (list): Lista de máscaras como arrays de NumPy.\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de imágenes aumentadas como arrays de NumPy.\n",
        "        list: Lista de máscaras aumentadas como arrays de NumPy.\n",
        "    \"\"\"\n",
        "    augmented_images = []\n",
        "    augmented_masks = []\n",
        "    augmented_classes = []\n",
        "\n",
        "    common_transform = [\n",
        "        # 1) Ajuste del tamaño a 256x256\n",
        "        transforms.Resize((256, 256)),\n",
        "\n",
        "        # 2) Recorte aleatorio para 224x224, simulando diferentes encuadres/zoom\n",
        "        transforms.RandomResizedCrop(\n",
        "            size=256,\n",
        "            scale=(0.8, 1.0),       # rango de escalado\n",
        "            ratio=(0.9, 1.1)        # rango de aspecto (ancho x alto)\n",
        "        ),\n",
        "\n",
        "        # 3) Rotación aleatoria moderada (±15 grados)\n",
        "        transforms.RandomRotation(degrees=30),\n",
        "\n",
        "        # 4) Flip horizontal aleatorio (probabilidad 0.5)\n",
        "        transforms.RandomHorizontalFlip(p=1),\n",
        "    ]\n",
        "\n",
        "    # Transformaciones para imágenes\n",
        "    img_transform = transforms.Compose(common_transform + [\n",
        "\n",
        "        # 5) Ajustes de color para simular distintas condiciones de iluminación\n",
        "        transforms.ColorJitter(\n",
        "            brightness=0.5,\n",
        "            contrast=0.2,\n",
        "            saturation=0.4,\n",
        "            hue=0.05\n",
        "        ),\n",
        "    ])\n",
        "\n",
        "    mask_transform = transforms.Compose(common_transform)\n",
        "\n",
        "    num_nuevas_por_imagen = 2\n",
        "    for img, mask, img_class in zip(images, masks, classes):\n",
        "        # Convertir la imagen y la máscara a PIL\n",
        "        img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        mask_pil = Image.fromarray(mask)\n",
        "\n",
        "        for i in range(num_nuevas_por_imagen):\n",
        "\n",
        "            # Aplicar las transformaciones\n",
        "            seed = random.randint(0, 2**32)  # Para asegurar que las mismas transformaciones se aplican a ambos\n",
        "            random.seed(seed)\n",
        "            augmented_img = img_transform(img_pil)\n",
        "            random.seed(seed)\n",
        "            augmented_mask = mask_transform(mask_pil)\n",
        "\n",
        "            # Convertir de nuevo a arrays de NumPy\n",
        "            augmented_images.append(np.array(augmented_img))\n",
        "            augmented_masks.append(np.array(augmented_mask))\n",
        "            augmented_classes.append(img_class)\n",
        "\n",
        "    return augmented_images, augmented_masks, augmented_classes\n",
        "\n",
        "augmented_images, augmented_masks, augmented_classes = augment_data(images, masks, classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zuLucIB9NRsa"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset personalizado para imágenes y máscaras, compatible con Mask R-CNN.\n",
        "    \"\"\"\n",
        "    def __init__(self, images, masks, classes, transforms=None):\n",
        "        \"\"\"\n",
        "        Inicializa el dataset.\n",
        "\n",
        "        Args:\n",
        "            images (list): Lista de imágenes como arrays de NumPy.\n",
        "            masks (list): Lista de máscaras como arrays de NumPy.\n",
        "            classes (list): Lista de etiquetas de clase correspondientes.\n",
        "            transform (callable, optional): Transformaciones a aplicar a las imágenes y máscaras.\n",
        "        \"\"\"\n",
        "        self.images = images\n",
        "        print(len(images))\n",
        "        self.masks = masks\n",
        "        self.classes = classes\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        mask = self.masks[idx]\n",
        "        mask = np.expand_dims(mask, axis=0)  # Añadir canal para compatibilidad con Torch\n",
        "        mask = torch.Tensor(mask)\n",
        "        label = self.classes[idx]\n",
        "\n",
        "        num_objs = 1\n",
        "\n",
        "        # Crear el target para Mask R-CNN\n",
        "        boxes = masks_to_boxes(mask)\n",
        "        area = (boxes[0][2] - boxes[0][0]) * (boxes[0][3] - boxes[0][1])\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        img = tv_tensors.Image(image)\n",
        "\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = tv_tensors.BoundingBoxes(\n",
        "            boxes, format=\"XYXY\", canvas_size=F.get_size(img)\n",
        "        )\n",
        "        target[\"masks\"] =  tv_tensors.Mask(mask)\n",
        "        target[\"labels\"] = torch.tensor([label], dtype=torch.int64)\n",
        "        target[\"image_id\"] = idx\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OTQXPgjpNRsc"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJvVmM5nNRsc",
        "outputId": "bac66117-57a6-4a08-d3c3-df9553a29198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "304\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "transforms = T.Compose(\n",
        "    [\n",
        "        T.ToDtype(torch.float, scale=True),\n",
        "        T.ToPureTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "dataset = CustomDataset(augmented_images, augmented_masks, augmented_classes, transforms)\n",
        "\n",
        "train_data, test_data = torch.utils.data.random_split(dataset, [0.7, 0.3])\n",
        "\n",
        "# define training and validation data loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d296-0lxNRsd"
      },
      "outputs": [],
      "source": [
        "def get_model_instance_segmentation(num_classes):\n",
        "  model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "  in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "  hidden_layer = model.roi_heads.mask_predictor.conv5_mask.out_channels\n",
        "\n",
        "  # and replace the mask predictor with a new one\n",
        "  model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
        "      in_features_mask, hidden_layer, num_classes\n",
        "  )\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552,
          "referenced_widgets": [
            "dd7f8a1c67564376ba222dde5bbf1d8b",
            "4d8e25d1f4404acca2c07c9c025a3109",
            "d652c0c80f874c4db53fdee41c0cdb55",
            "41daa10fe08f461283d23d26e18f7abd",
            "1c889970dc1748498cb3cae9f39791d6",
            "26d0baa3e39745d5a2dc69742ba7dd4e",
            "bd6b52e777d84d81b2c2808f5f28cbbd",
            "70eaeff55b134b0ab495f243cc537a55",
            "beb23ac12755446587733208d57e1f74",
            "369ead29a9574d358bf0e32336fd80d4",
            "bfe1674327b342269b9fbfbc7f186a4b"
          ]
        },
        "id": "qcd5P9CNNRsd",
        "outputId": "cd369c57-3e3e-48f9-a264-96d8b57e05fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = get_model_instance_segmentation(3)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "t_loss = np.zeros(epochs)\n",
        "\n",
        "pbar = tqdm(range(1, epochs + 1))  # tdqm permet tenir text dinàmic\n",
        "\n",
        "for epoch in pbar:\n",
        "\n",
        "    train_loss = 0\n",
        "    val_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for images, targets in train_loader:\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [\n",
        "            {\n",
        "                k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
        "                for k, v in t.items()\n",
        "            } for t in targets\n",
        "        ]\n",
        "\n",
        "        images = [image.permute(2, 0, 1) for image in images]\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        train_loss += losses.item()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    t_loss[epoch - 1] = train_loss\n",
        "\n",
        "\n",
        "    pl.clf()\n",
        "    pl.figure(figsize=(12, 4))\n",
        "    pl.plot(t_loss[:epoch], label=\"train\")\n",
        "    pl.legend()\n",
        "    pl.xlim(0, epochs)\n",
        "    pl.xticks(range(0, epochs, 1), range(1, epochs + 1, 1))\n",
        "\n",
        "    display.display(pl.gcf())\n",
        "    display.clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import draw_segmentation_masks, draw_bounding_boxes\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory_summary(device=torch.device('cuda'), abbreviated=True))\n",
        "num_batches_to_display = 2\n",
        "batches_displayed = 0\n",
        "model.eval()\n",
        "test_list = list(test_loader)\n",
        "\n",
        "for images, targets in train_loader:\n",
        "    images = list(image.to(device) for image in images)\n",
        "    targets = [\n",
        "        {\n",
        "            k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
        "            for k, v in t.items()\n",
        "        } for t in targets\n",
        "    ]\n",
        "\n",
        "    images = [image.permute(2, 0, 1) for image in images]\n",
        "    res = model(images)\n",
        "\n",
        "    for i in range(len(images)):\n",
        "      drawn_boxes = draw_bounding_boxes(images[i], res[i][\"boxes\"], colors=\"red\")\n",
        "      mask_superposed = (\n",
        "          draw_segmentation_masks(\n",
        "              images[i], masks=(res[i][\"masks\"][0, 0, :, :] > 0.1), alpha=0.8, colors=\"blue\"\n",
        "          )\n",
        "          .detach()\n",
        "          .cpu()\n",
        "      )\n",
        "      fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
        "      ax[0].imshow(mask_superposed.permute(1, 2, 0))\n",
        "      ax[0].imshow(drawn_boxes.permute(1, 2, 0).cpu().numpy());\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "# while batches_displayed < num_batches_to_display:\n",
        "#     images = list(image.to(device) for image in images)\n",
        "#     images = [image.permute(2, 0, 1) for image in images]\n",
        "#     print(images[0].shape)\n",
        "\n",
        "#     # Predicción\n",
        "#     res = model(images)\n",
        "\n",
        "#     # Calcular el número de filas necesarias\n",
        "#     num_images = len(images) * 2\n",
        "#     num_cols = 4\n",
        "#     num_rows = (num_images + num_cols - 1) // num_cols  # Redondear hacia arriba\n",
        "\n",
        "#     fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n",
        "#     axes = axes.flatten()  # Aplanar la matriz de ejes para iterar fácilmente\n",
        "\n",
        "#     for i, (img, ax) in enumerate(zip(res, axes)):\n",
        "#         mask_superposed = (\n",
        "#             draw_segmentation_masks(\n",
        "#                 img, masks=(res[0][\"masks\"][0, 0, :, :] > 0.1), alpha=0.8, colors=\"blue\"\n",
        "#             )\n",
        "#             .detach()\n",
        "#             .cpu()\n",
        "#         )\n",
        "\n",
        "#         drawn_boxes = draw_bounding_boxes(img, res[0][\"boxes\"], colors=\"red\")\n",
        "#         ax.imshow(mask_superposed.permute(1, 2, 0))\n",
        "#         ax.imshow(drawn_boxes.permute(1, 2, 0).cpu().numpy());\n",
        "\n",
        "#     # Ocultar los ejes sobrantes si hay menos imágenes que espacios\n",
        "#     for ax in axes[num_images:]:\n",
        "#         ax.axis(\"off\")\n",
        "\n",
        "#     plt.tight_layout()  # Ajustar los espacios en el plot\n",
        "#     plt.show()\n",
        "\n",
        "#     batches_displayed += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "id": "jGarZbUYqxYf",
        "outputId": "81d3fe4a-b5f8-4b4b-a6b8-be976260b22d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 2            |        cudaMalloc retries: 3         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  14393 MiB |  14515 MiB |  12177 GiB |  12163 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  14393 MiB |  14515 MiB |  12177 GiB |  12163 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |  14370 MiB |  14491 MiB |  12157 GiB |  12143 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |  14742 MiB |  14744 MiB |  26606 MiB |  11864 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory | 356533 KiB |   4536 MiB |   8563 GiB |   8563 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |    1043    |    1141    |     829 K  |     828 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |    1043    |    1141    |     829 K  |     828 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |     105    |     107    |     142    |      37    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      63    |     128    |  401670    |  401607    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 626.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 83.06 MiB is free. Process 406159 has 14.66 GiB memory in use. Of the allocated memory 14.19 GiB is allocated by PyTorch, and 348.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5c782468a576>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     )\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/backbone_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mout_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 626.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 83.06 MiB is free. Process 406159 has 14.66 GiB memory in use. Of the allocated memory 14.19 GiB is allocated by PyTorch, and 348.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rjLKyute1N3v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd7f8a1c67564376ba222dde5bbf1d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d8e25d1f4404acca2c07c9c025a3109",
              "IPY_MODEL_d652c0c80f874c4db53fdee41c0cdb55",
              "IPY_MODEL_41daa10fe08f461283d23d26e18f7abd"
            ],
            "layout": "IPY_MODEL_1c889970dc1748498cb3cae9f39791d6"
          }
        },
        "4d8e25d1f4404acca2c07c9c025a3109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26d0baa3e39745d5a2dc69742ba7dd4e",
            "placeholder": "​",
            "style": "IPY_MODEL_bd6b52e777d84d81b2c2808f5f28cbbd",
            "value": "100%"
          }
        },
        "d652c0c80f874c4db53fdee41c0cdb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70eaeff55b134b0ab495f243cc537a55",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_beb23ac12755446587733208d57e1f74",
            "value": 10
          }
        },
        "41daa10fe08f461283d23d26e18f7abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_369ead29a9574d358bf0e32336fd80d4",
            "placeholder": "​",
            "style": "IPY_MODEL_bfe1674327b342269b9fbfbc7f186a4b",
            "value": " 10/10 [06:33&lt;00:00, 39.28s/it]"
          }
        },
        "1c889970dc1748498cb3cae9f39791d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26d0baa3e39745d5a2dc69742ba7dd4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd6b52e777d84d81b2c2808f5f28cbbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70eaeff55b134b0ab495f243cc537a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb23ac12755446587733208d57e1f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "369ead29a9574d358bf0e32336fd80d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfe1674327b342269b9fbfbc7f186a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}