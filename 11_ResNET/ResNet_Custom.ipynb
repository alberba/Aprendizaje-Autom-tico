{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e990e6801202c40d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/bmalcover/aa_2425/blob/main/11_ResNET/ResNet_Custom.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272d21b93244ea6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:29:03.423268Z",
     "start_time": "2024-11-14T12:28:57.306625Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\miniconda3\\envs\\ia_2024\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a26d98415d24c4",
   "metadata": {},
   "source": [
    "# Introducció\n",
    "\n",
    "En aquesta pràctica treballarem amb l'arquitectura ResNet (Residual Network), centrant-nos en el concepte clau dels blocs residuals, que ja hem explorat a classe. Recordem breument la principal innovació d'aquestes: el bloc residual. Aquest introdueix una connexió directa (*shortcut connection*) entre l'entrada i la sortida d'un grup de capes, tal com es representa a continuació:\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathcal{F}(\\mathbf{x}, \\{W_i\\}) + \\mathbf{x}\n",
    "$$\n",
    "\n",
    "On:\n",
    "- $\\mathbf{x}$ és l'entrada del bloc.\n",
    "- $\\mathcal{F}(\\mathbf{x}, \\{W_i\\})$ és la transformació no lineal aplicada per les capes internes (normalment convolucions, normalització i ReLU).\n",
    "- $\\mathbf{y}$ és la sortida, que combina l'entrada original xx amb la transformació.\n",
    "\n",
    "Aquest simple però efectiu mecanisme permet que el model \"aprengui\" només la diferència (o residual) entre l'entrada i la sortida esperada, en lloc de l'objectiu complet. Això facilita l'entrenament i redueix el risc de degradació del rendiment en xarxes profundes.\n",
    "\n",
    "A classe hem vist que aquests blocs residuals són la base de diferents variants de ResNet, com ara ResNet-18, ResNet-50, etc., amb diferències en la profunditat i el nombre de blocs. Ara posarem en pràctica aquest coneixement treballant amb ResNets per a tasques de classificació d’imatges\n",
    "\n",
    "# Cream mòduls amb Pytorch\n",
    "\n",
    "En aquesta pràctica aprendrem a definir mòduls personalitzats en PyTorch utilitzant la classe base ``torch.nn.Module``. Aquesta classe permet encapsular les capes i operacions d’una xarxa neuronal, facilitant-ne la reutilització i el manteniment.\n",
    "\n",
    "**Pasos per crear un mòdul en Pytorch:**\n",
    "1. **Heretar de nn.Module**. Tots els mòduls personalitzats en PyTorch han de derivar de la classe base torch.nn.Module.\n",
    "2. **Definir les capes en el constructor __init__.** Al constructor del mòdul (__init__), s’han d’inicialitzar les capes que s’utilitzaran, com ara convolucions, capes lineals o funcions d’activació.\n",
    "3. **Implementar la funció forward.** Aquesta funció defineix com flueixen les dades a través del mòdul. Aquí s’apliquen les capes definides al constructor de manera seqüencial o segons sigui necessari.\n",
    "\n",
    "\n",
    "## Cream un bloc residual\n",
    "\n",
    "**Revisar sessió teòrica**\n",
    "\n",
    "El nostre bloc residual tendrà dues capes convolucionals, batch norm i emprarà ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6911c9d4317fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            padding='same',\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            padding='same',\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.downsample = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=(3, 3),\n",
    "                    padding='same',\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x) if self.downsample else x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu()\n",
    "        x = self.conv2()\n",
    "        x = self.bn2()\n",
    "        x = self.relu(x + identity)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f6ef0442c6868b",
   "metadata": {},
   "source": [
    "## Una VGG16 residual\n",
    "\n",
    "Una vegada el tenim implementat farem dos models:\n",
    "1. Model VGG16 **normal**. Un model com el que vàrem veure la setmana passada sense preentranement.\n",
    "2. Model VGG16 **ampliat**. Heu d'afegir a una VGG16 dos blocs residuals al final de l'extractor de característiques. Per fer-ho s'ha d'emprar la mateixa estratègia que heu vist a les sessions anteriors per fer fine-tunning.\n",
    "\n",
    "Entrena ambdós models amb el conjunt de dades [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist), i contesta a la següent pregunta:\n",
    "\n",
    "- És el mateix resultat una xarxa que l'altra? Si és així o no diguès per què?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d69bf892ad11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD = True\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "train= datasets.FashionMNIST(\"../data\", train=True, download=DOWNLOAD, transform=transform)\n",
    "test=datasets.FashionMNIST(\"../data\", train=False, download=DOWNLOAD, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7697fa2e6da352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16()\n",
    "\n",
    "print(vgg16.classifier)\n",
    "\n",
    "vgg16.features.append(ResidualBlock(512, 512))\n",
    "vgg16.features.append(ResidualBlock(512, 512))\n",
    "vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7d9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.features[0] = torch.nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3, 3), stride=1, padding='same')\n",
    "vgg16.classifier[-1] = torch.nn.Linear(4096,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287d824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = vgg16.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c097c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(vgg16.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f264a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m running_test_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m running_test_acc_cnn \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m(\u001b[38;5;28mrange\u001b[39m(EPOCHS), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÈpoques\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     10\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m     batch_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "running_loss = []\n",
    "running_acc = []\n",
    "\n",
    "running_test_loss = []\n",
    "running_test_acc_cnn = []\n",
    "\n",
    "for t in tqdm(range(EPOCHS), desc=\"Èpoques\"):\n",
    "    batch_loss = 0\n",
    "    batch_acc = 0\n",
    "\n",
    "    i_batch = 1\n",
    "\n",
    "    for i_batch, (x, y) in tqdm(enumerate(train_loader), desc=f\"Batches (Època {t + 1})\"):\n",
    "        vgg16.train()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = vgg16(x.to(device))\n",
    "\n",
    "        y = y.to(device)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        vgg16.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            optimizer.step()\n",
    "\n",
    "        vgg16.eval()\n",
    "\n",
    "        y_pred = vgg16(x.to(device))\n",
    "        batch_loss += (loss_fn(y_pred, y).detach())\n",
    "\n",
    "        y_pred_class = torch.argmax(y_pred.detach().cpu(), dim=1).numpy()\n",
    "        batch_acc += accuracy_score(y.detach().cpu().numpy(), y_pred_class)\n",
    "\n",
    "    running_loss.append(batch_loss / (i_batch + 1))\n",
    "    running_acc.append(batch_acc / (i_batch + 1))\n",
    "\n",
    "    batch_test_loss = 0\n",
    "    batch_test_acc = 0\n",
    "\n",
    "    vgg16.eval()\n",
    "    for i_batch, (x, y) in enumerate(test_loader):\n",
    "        y_pred = vgg16(x.to(device))\n",
    "        batch_test_loss += (loss_fn(y_pred, y.to(device)).detach())\n",
    "\n",
    "        y_pred_class = torch.argmax(y_pred.detach().cpu(), dim=1).numpy()\n",
    "        batch_test_acc += accuracy_score(y, y_pred_class)\n",
    "\n",
    "    running_test_loss.append(batch_test_loss / (i_batch + 1))\n",
    "    running_test_acc_cnn.append(batch_test_acc / (i_batch + 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d4bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
